{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Debugging - Step 1: Embedding Tests (Simplified)\n",
    "\n",
    "**Problem**: RAG findet kaum relevante Chunks bei deutschen/englischen Queries\n",
    "\n",
    "**Hypothese**: Das Embedding-Modell ist schlecht für multilinguale Inhalte\n",
    "\n",
    "**Test**: Direkt mit sentence-transformers testen (umgeht dependency issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Direkt mit sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianwegener/Projects/crawl4ai-mcp-server/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sentence-transformers loaded\n",
      "✅ Helper functions ready\n"
     ]
    }
   ],
   "source": [
    "# Einfacher direkter Ansatz\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"✅ sentence-transformers loaded\")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Simple cosine similarity function\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(\"✅ Helper functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data - Realistische RAG-Beispiele\n",
    "\n",
    "Das sind typische Inhalte aus technischer Dokumentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Test Setup:\n",
      "   - 3 deutsche Dokumente\n",
      "   - 3 englische Dokumente\n",
      "   - 3 Test-Queries\n"
     ]
    }
   ],
   "source": [
    "# Deutsche Tech-Texte (typische Chunk-Inhalte)\n",
    "german_docs = [\n",
    "    \"Die Vektorsuche in ChromaDB verwendet Cosinus-Ähnlichkeit für semantische Suchen.\",\n",
    "    \"Chunking-Strategien sollten bei technischen Dokumentationen header-bewusst sein.\",\n",
    "    \"Der Similarity-Threshold von 0.7 ist oft zu restriktiv für multilinguale Inhalte.\"\n",
    "]\n",
    "\n",
    "# Englische Tech-Texte (semantisch verwandt)\n",
    "english_docs = [\n",
    "    \"Vector search in ChromaDB uses cosine similarity for semantic searches.\",\n",
    "    \"Chunking strategies should be header-aware for technical documentation.\",\n",
    "    \"The similarity threshold of 0.7 is often too restrictive for multilingual content.\"\n",
    "]\n",
    "\n",
    "# Typische User-Queries\n",
    "queries = {\n",
    "    \"german\": \"Wie funktioniert Vektorsuche?\",\n",
    "    \"english\": \"How does vector search work?\",\n",
    "    \"mixed\": \"ChromaDB similarity threshold\"\n",
    "}\n",
    "\n",
    "print(f\"📝 Test Setup:\")\n",
    "print(f\"   - {len(german_docs)} deutsche Dokumente\")\n",
    "print(f\"   - {len(english_docs)} englische Dokumente\") \n",
    "print(f\"   - {len(queries)} Test-Queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Aktuelles Modell (all-MiniLM-L6-v2)\n",
    "\n",
    "Das ist das Modell, das momentan in deinem RAG-System verwendet wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Loading current model: all-MiniLM-L6-v2\n",
      "📐 Max sequence length: 256\n",
      "📊 Embedding dimension: 384\n",
      "\n",
      "🔄 Encoding documents...\n",
      "✅ Encoded 3 documents\n"
     ]
    }
   ],
   "source": [
    "# Das aktuelle RAG-Modell laden\n",
    "print(\"🤖 Loading current model: all-MiniLM-L6-v2\")\n",
    "current_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(f\"📐 Max sequence length: {current_model.max_seq_length}\")\n",
    "print(f\"📊 Embedding dimension: {current_model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Encode all documents\n",
    "print(\"\\n🔄 Encoding documents...\")\n",
    "de_embeddings = current_model.encode(german_docs)\n",
    "en_embeddings = current_model.encode(english_docs)\n",
    "\n",
    "print(f\"✅ Encoded {len(de_embeddings + en_embeddings)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Cross-Language Similarity Matrix\n",
    "\n",
    "**Das ist der kritische Test**: Erkennt das Modell, dass deutsche und englische Texte mit gleicher Bedeutung ähnlich sind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Cross-Language Similarity Analysis\n",
      "============================================================\n",
      "\n",
      "🇩🇪 German Doc 1: Die Vektorsuche in ChromaDB verwendet Cosinus-Ähnl...\n",
      "   🎯 vs EN Doc 1: 0.410\n",
      "       🇬🇧 Vector search in ChromaDB uses cosine similarity f...\n",
      "       ❌ Schlecht erkannt!\n",
      "      vs EN Doc 2: -0.002\n",
      "      vs EN Doc 3: 0.094\n",
      "\n",
      "🇩🇪 German Doc 2: Chunking-Strategien sollten bei technischen Dokume...\n",
      "      vs EN Doc 1: 0.202\n",
      "   🎯 vs EN Doc 2: 0.594\n",
      "       🇬🇧 Chunking strategies should be header-aware for tec...\n",
      "       ⚠️  Okay erkannt\n",
      "      vs EN Doc 3: 0.244\n",
      "\n",
      "🇩🇪 German Doc 3: Der Similarity-Threshold von 0.7 ist oft zu restri...\n",
      "      vs EN Doc 1: 0.318\n",
      "      vs EN Doc 2: 0.144\n",
      "   🎯 vs EN Doc 3: 0.683\n",
      "       🇬🇧 The similarity threshold of 0.7 is often too restr...\n",
      "       ⚠️  Okay erkannt\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 Cross-Language Similarity Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (de_text, de_emb) in enumerate(zip(german_docs, de_embeddings)):\n",
    "    print(f\"\\n🇩🇪 German Doc {i+1}: {de_text[:50]}...\")\n",
    "    \n",
    "    for j, (en_text, en_emb) in enumerate(zip(english_docs, en_embeddings)):\n",
    "        similarity = cosine_similarity(de_emb, en_emb)\n",
    "        \n",
    "        # Erwartete Paare (gleiche Bedeutung) highlighten\n",
    "        marker = \"🎯\" if i == j else \"  \"\n",
    "        \n",
    "        print(f\"   {marker} vs EN Doc {j+1}: {similarity:.3f}\")\n",
    "        if i == j:\n",
    "            print(f\"       🇬🇧 {en_text[:50]}...\")\n",
    "            # Bewertung der Similarity\n",
    "            if similarity > 0.7:\n",
    "                print(f\"       ✅ Sehr gut erkannt!\")\n",
    "            elif similarity > 0.5:\n",
    "                print(f\"       ⚠️  Okay erkannt\")\n",
    "            else:\n",
    "                print(f\"       ❌ Schlecht erkannt!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Query-Retrieval Simulation\n",
    "\n",
    "Simulieren wir eine echte RAG-Suche: Welche Dokumente würden für jede Query gefunden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Query Test: german\n",
      "Query: 'Wie funktioniert Vektorsuche?'\n",
      "--------------------------------------------------\n",
      "Top Results:\n",
      "  1. [0.502] 🇩🇪 Doc1: Die Vektorsuche in ChromaDB verwendet Cosinus-Ähnlichkeit fü...\n",
      "  2. [0.280] 🇩🇪 Doc3: Der Similarity-Threshold von 0.7 ist oft zu restriktiv für m...\n",
      "  3. [0.264] 🇩🇪 Doc2: Chunking-Strategien sollten bei technischen Dokumentationen ...\n",
      "\n",
      "📊 Threshold Analysis:\n",
      "   - Above 0.7: 0/6 docs (current RAG threshold)\n",
      "   - Above 0.5: 1/6 docs\n",
      "   - Above 0.3: 1/6 docs\n",
      "   ❌ Bei 0.7 Threshold: KEINE Ergebnisse!\n",
      "\n",
      "🔍 Query Test: english\n",
      "Query: 'How does vector search work?'\n",
      "--------------------------------------------------\n",
      "Top Results:\n",
      "  1. [0.577] 🇬🇧 Doc4: Vector search in ChromaDB uses cosine similarity for semanti...\n",
      "  2. [0.167] 🇩🇪 Doc2: Chunking-Strategien sollten bei technischen Dokumentationen ...\n",
      "  3. [0.119] 🇩🇪 Doc3: Der Similarity-Threshold von 0.7 ist oft zu restriktiv für m...\n",
      "\n",
      "📊 Threshold Analysis:\n",
      "   - Above 0.7: 0/6 docs (current RAG threshold)\n",
      "   - Above 0.5: 1/6 docs\n",
      "   - Above 0.3: 1/6 docs\n",
      "   ❌ Bei 0.7 Threshold: KEINE Ergebnisse!\n",
      "\n",
      "🔍 Query Test: mixed\n",
      "Query: 'ChromaDB similarity threshold'\n",
      "--------------------------------------------------\n",
      "Top Results:\n",
      "  1. [0.611] 🇬🇧 Doc4: Vector search in ChromaDB uses cosine similarity for semanti...\n",
      "  2. [0.424] 🇩🇪 Doc1: Die Vektorsuche in ChromaDB verwendet Cosinus-Ähnlichkeit fü...\n",
      "  3. [0.394] 🇩🇪 Doc3: Der Similarity-Threshold von 0.7 ist oft zu restriktiv für m...\n",
      "\n",
      "📊 Threshold Analysis:\n",
      "   - Above 0.7: 0/6 docs (current RAG threshold)\n",
      "   - Above 0.5: 1/6 docs\n",
      "   - Above 0.3: 4/6 docs\n",
      "   ❌ Bei 0.7 Threshold: KEINE Ergebnisse!\n"
     ]
    }
   ],
   "source": [
    "# Kombiniere alle Dokumente für die Suche\n",
    "all_docs = german_docs + english_docs\n",
    "all_embeddings = np.vstack([de_embeddings, en_embeddings])\n",
    "\n",
    "def test_query(query_text, query_name):\n",
    "    print(f\"\\n🔍 Query Test: {query_name}\")\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Query embedding\n",
    "    query_emb = current_model.encode([query_text])[0]\n",
    "    \n",
    "    # Similarity zu allen Dokumenten\n",
    "    similarities = []\n",
    "    for i, (doc, doc_emb) in enumerate(zip(all_docs, all_embeddings)):\n",
    "        sim = cosine_similarity(query_emb, doc_emb)\n",
    "        lang = \"🇩🇪\" if i < len(german_docs) else \"🇬🇧\"\n",
    "        similarities.append((sim, doc, lang, i+1))\n",
    "    \n",
    "    # Sortiere nach Relevanz\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Zeige Results\n",
    "    print(\"Top Results:\")\n",
    "    for rank, (score, doc, lang, doc_id) in enumerate(similarities[:3], 1):\n",
    "        print(f\"  {rank}. [{score:.3f}] {lang} Doc{doc_id}: {doc[:60]}...\")\n",
    "    \n",
    "    # RAG-Threshold Analysis\n",
    "    above_07 = sum(1 for score, _, _, _ in similarities if score >= 0.7)\n",
    "    above_05 = sum(1 for score, _, _, _ in similarities if score >= 0.5)\n",
    "    above_03 = sum(1 for score, _, _, _ in similarities if score >= 0.3)\n",
    "    \n",
    "    print(f\"\\n📊 Threshold Analysis:\")\n",
    "    print(f\"   - Above 0.7: {above_07}/{len(similarities)} docs (current RAG threshold)\")\n",
    "    print(f\"   - Above 0.5: {above_05}/{len(similarities)} docs\")\n",
    "    print(f\"   - Above 0.3: {above_03}/{len(similarities)} docs\")\n",
    "    \n",
    "    if above_07 == 0:\n",
    "        print(f\"   ❌ Bei 0.7 Threshold: KEINE Ergebnisse!\")\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# Teste alle Queries\n",
    "results = {}\n",
    "for query_name, query_text in queries.items():\n",
    "    results[query_name] = test_query(query_text, query_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse: Was sehen wir?\n",
    "\n",
    "**Jetzt können wir konkret bewerten:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ZUSAMMENFASSUNG DER ERKENNTNISSE\n",
      "==================================================\n",
      "📊 Cross-Language Performance:\n",
      "   - Durchschnitt DE<->EN: 0.562\n",
      "   - Range: 0.410 - 0.683\n",
      "   ⚠️  PROBLEM: Mäßige Cross-Language Performance\n",
      "\n",
      "🔍 Query Performance:\n",
      "   - german: Best=0.502, Above0.7=0\n",
      "   - english: Best=0.577, Above0.7=0\n",
      "   - mixed: Best=0.611, Above0.7=0\n",
      "\n",
      "💡 EMPFEHLUNGEN:\n",
      "   1. 📉 Similarity Threshold anpassen\n",
      "   2. 🔧 Query-Enhancement implementieren\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 ZUSAMMENFASSUNG DER ERKENNTNISSE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cross-Language Performance\n",
    "cross_lang_scores = []\n",
    "for i in range(len(german_docs)):\n",
    "    score = cosine_similarity(de_embeddings[i], en_embeddings[i])\n",
    "    cross_lang_scores.append(score)\n",
    "\n",
    "avg_cross_lang = np.mean(cross_lang_scores)\n",
    "print(f\"📊 Cross-Language Performance:\")\n",
    "print(f\"   - Durchschnitt DE<->EN: {avg_cross_lang:.3f}\")\n",
    "print(f\"   - Range: {min(cross_lang_scores):.3f} - {max(cross_lang_scores):.3f}\")\n",
    "\n",
    "if avg_cross_lang < 0.5:\n",
    "    print(f\"   ❌ PROBLEM: Sehr schlechte Cross-Language Performance!\")\n",
    "elif avg_cross_lang < 0.7:\n",
    "    print(f\"   ⚠️  PROBLEM: Mäßige Cross-Language Performance\")\n",
    "else:\n",
    "    print(f\"   ✅ Gute Cross-Language Performance\")\n",
    "\n",
    "# Query Performance\n",
    "print(f\"\\n🔍 Query Performance:\")\n",
    "for query_name, query_results in results.items():\n",
    "    best_score = query_results[0][0]\n",
    "    above_threshold = sum(1 for score, _, _, _ in query_results if score >= 0.7)\n",
    "    \n",
    "    print(f\"   - {query_name}: Best={best_score:.3f}, Above0.7={above_threshold}\")\n",
    "    \n",
    "print(f\"\\n💡 EMPFEHLUNGEN:\")\n",
    "if avg_cross_lang < 0.5:\n",
    "    print(f\"   1. 🚨 DRINGEND: Multilingual Model verwenden!\")\n",
    "    print(f\"   2. 📉 Similarity Threshold auf 0.3 reduzieren\")\n",
    "    print(f\"   3. 🧪 Test: paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "else:\n",
    "    print(f\"   1. 📉 Similarity Threshold anpassen\")\n",
    "    print(f\"   2. 🔧 Query-Enhancement implementieren\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**Based on the results above, our next notebook will test:**\n",
    "\n",
    "1. **Multilingual Models**: `paraphrase-multilingual-MiniLM-L12-v2`\n",
    "2. **Optimized Thresholds**: Find the sweet spot for your use case\n",
    "3. **Query Enhancement**: Add synonyms and translations\n",
    "\n",
    "---\n",
    "\n",
    "🎯 **This notebook shows the EXACT problem** - no complex RAG pipeline needed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
